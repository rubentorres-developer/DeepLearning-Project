{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning - Project\n",
    "\n",
    "## Parking Space Detection\n",
    "\n",
    "### Group 02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports & Global Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "ORIGINAL_DATASET_PATH = \"./datasets/original\"\n",
    "TRANSFORMED_DATASET_PATH = \"./datasets/transformed\"\n",
    "TRAINING_DATASET_PATH = \"./datasets/training\"\n",
    "VALIDATION_DATASET_PATH = \"./datasets/validation\"\n",
    "TESTING_DATASET_PATH = \"./datasets/testing\"\n",
    "\n",
    "TRAINING_RATIO = 0.8\n",
    "VALIDATION_RATIO = 0.15\n",
    "TESTING_RATIO = 0.05\n",
    "\n",
    "GITKEEP = \".gitkeep\"\n",
    "\n",
    "IMAGE_WIDTH = 1280\n",
    "IMAGE_HEIGHT = 720\n",
    "\n",
    "CLASS_MAPPING = {\"0\": 0, \"1\": 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Pipeline\n",
    "\n",
    "# 1.1. Transforming\n",
    "\n",
    "First we start by transforming our original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, _, files in os.walk(ORIGINAL_DATASET_PATH):\n",
    "    for file in files:\n",
    "        if file == GITKEEP:\n",
    "            continue\n",
    "        source = os.path.join(root, file)\n",
    "        destination = os.path.join(TRANSFORMED_DATASET_PATH, file)\n",
    "        shutil.move(source, destination)\n",
    "\n",
    "for dir in os.listdir(ORIGINAL_DATASET_PATH):\n",
    "    if not os.path.isdir(dir):\n",
    "        continue\n",
    "    path = os.path.join(ORIGINAL_DATASET_PATH, dir)\n",
    "    shutil.rmtree(path)\n",
    "\n",
    "print(\"Merge complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Create the Labels\n",
    "\n",
    "We'll convert the labels from XML to TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_files = [\n",
    "    file for file in os.listdir(TRANSFORMED_DATASET_PATH) if file.endswith(\".xml\")\n",
    "]\n",
    "\n",
    "for xml_file in xml_files:\n",
    "    xml_path = os.path.join(TRANSFORMED_DATASET_PATH, xml_file)\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    txt_filename = os.path.splitext(xml_file)[0] + \".txt\"\n",
    "    txt_path = os.path.join(TRANSFORMED_DATASET_PATH, txt_filename)\n",
    "    with open(txt_path, \"w\") as txt_file:\n",
    "        for space in root.findall(\"space\"):\n",
    "            occupied = space.get(\"occupied\")\n",
    "            class_index = CLASS_MAPPING.get(occupied, -1)\n",
    "            if class_index == -1:\n",
    "                continue\n",
    "            rotated_rect = space.find(\"rotatedRect\")\n",
    "            center = rotated_rect.find(\"center\")\n",
    "            size = rotated_rect.find(\"size\")\n",
    "            x = float(center.get(\"x\")) / IMAGE_WIDTH\n",
    "            y = float(center.get(\"y\")) / IMAGE_HEIGHT\n",
    "            w = float(size.get(\"w\")) / IMAGE_WIDTH\n",
    "            h = float(size.get(\"h\")) / IMAGE_HEIGHT\n",
    "            txt_file.write(f\"{class_index} {x} {y} {w} {h}\\n\")\n",
    "    os.remove(xml_path)\n",
    "\n",
    "print(\"Conversion complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = [f for f in os.listdir(TRANSFORMED_DATASET_PATH) if f.endswith(\".jpg\")]\n",
    "print(image_files)\n",
    "\n",
    "num_samples = len(image_files)\n",
    "num_train = int(TRAINING_RATIO * num_samples)\n",
    "num_test = int(TESTING_RATIO * num_samples)\n",
    "num_val = num_samples - num_train - num_test\n",
    "\n",
    "random.shuffle(image_files)\n",
    "\n",
    "train_files = image_files[:num_train]\n",
    "test_files = image_files[num_train:num_train + num_test]\n",
    "val_files = image_files[num_train + num_test:]\n",
    "\n",
    "# Move corresponding txt files along with images\n",
    "for folder, files in [(TRAINING_DATASET_PATH, train_files), (TESTING_DATASET_PATH, test_files), (VALIDATION_DATASET_PATH, val_files)]:\n",
    "    for file in files:\n",
    "        # Move image file\n",
    "        source_image_path = os.path.join(TRANSFORMED_DATASET_PATH, file)\n",
    "        destination_image_path = os.path.join(folder + '/images', file)\n",
    "        shutil.move(source_image_path, destination_image_path)\n",
    "        \n",
    "        # Move corresponding txt file\n",
    "        txt_file = os.path.splitext(file)[0] + \".txt\"\n",
    "        source_txt_path = os.path.join(TRANSFORMED_DATASET_PATH, txt_file)\n",
    "        destination_txt_path = os.path.join(folder + '/labels', txt_file)\n",
    "        shutil.move(source_txt_path, destination_txt_path)\n",
    "\n",
    "print(\"Data split into train, test, and val sets.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
