{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9S0m7xAoiZy"
      },
      "source": [
        "# Deep Learning - Project\n",
        "\n",
        "## Parking Space Detection\n",
        "\n",
        "### Group 02\n",
        "\n",
        "#### Rúben Torres fc62531\n",
        "#### João Martins fc62532"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TQl15ZdVoiZ0",
        "outputId": "64d7f069-24c2-4a72-fcc1-8b0ac3465750"
      },
      "outputs": [],
      "source": [
        "# RUN ONLY IN Google Colab\n",
        "#!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zD5xSPLOorsr",
        "outputId": "69ea8281-ccb9-45cf-8146-8532efa0af39"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qgNyjq7KpdP9",
        "outputId": "26e6e7a1-4438-4685-9c4f-c9b71e121354"
      },
      "outputs": [],
      "source": [
        "#!unzip /content/drive/MyDrive/datasets -d ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZFqZQafoiZ2"
      },
      "source": [
        "# 0. Imports & Global Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DASAZk1moiZ2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "ORIGINAL_DATASET_PATH = \"./datasets/original\"\n",
        "TRANSFORMED_DATASET_PATH = \"./datasets/transformed\"\n",
        "TRAINING_DATASET_PATH = \"./datasets/train\"\n",
        "VALIDATION_DATASET_PATH = \"./datasets/val\"\n",
        "TESTING_DATASET_PATH = \"./datasets/test\"\n",
        "\n",
        "TRAINING_RATIO = 0.7\n",
        "VALIDATION_RATIO = 0.15\n",
        "TESTING_RATIO = 0.15\n",
        "\n",
        "GITKEEP = \".gitkeep\"\n",
        "DS_STORE = \".DS_Store\"\n",
        "\n",
        "IMAGE_WIDTH = 1280\n",
        "IMAGE_HEIGHT = 720\n",
        "\n",
        "CLASS_MAPPING = {\"0\": 0, \"1\": 1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSttuf80oiZ3"
      },
      "source": [
        "# 1. Data Pipeline\n",
        "\n",
        "# 1.1. Transforming\n",
        "\n",
        "First we start by transforming our original dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27YgKgivoiZ3",
        "outputId": "94d08cee-89e8-4fe1-c429-52c73b28d456"
      },
      "outputs": [],
      "source": [
        "for root, _, files in os.walk(ORIGINAL_DATASET_PATH):\n",
        "    for file in files:\n",
        "        if file == GITKEEP or file == DS_STORE:\n",
        "            continue\n",
        "        source = os.path.join(root, file)\n",
        "        destination = os.path.join(TRANSFORMED_DATASET_PATH, file)\n",
        "        # print(destination)\n",
        "        shutil.move(source, destination)\n",
        "\n",
        "for dir in os.listdir(ORIGINAL_DATASET_PATH):\n",
        "    if not os.path.isdir(dir):\n",
        "        continue\n",
        "    path = os.path.join(ORIGINAL_DATASET_PATH, dir)\n",
        "    shutil.rmtree(path)\n",
        "\n",
        "print(\"Merge complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nO7GeDpRoiZ4"
      },
      "source": [
        "## 1.2. Create the Labels\n",
        "\n",
        "We'll convert the labels from XML to TXT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgKi8MOmoiZ4",
        "outputId": "841bba08-49f2-449e-e5a4-b5591eebce56"
      },
      "outputs": [],
      "source": [
        "xml_files = [\n",
        "    file for file in os.listdir(TRANSFORMED_DATASET_PATH) if file.endswith(\".xml\")\n",
        "]\n",
        "\n",
        "for xml_file in xml_files:\n",
        "    xml_path = os.path.join(TRANSFORMED_DATASET_PATH, xml_file)\n",
        "    tree = ET.parse(xml_path)\n",
        "    root = tree.getroot()\n",
        "    txt_filename = os.path.splitext(xml_file)[0] + \".txt\"\n",
        "    txt_path = os.path.join(TRANSFORMED_DATASET_PATH, txt_filename)\n",
        "    with open(txt_path, \"w\") as txt_file:\n",
        "        for space in root.findall(\"space\"):\n",
        "            occupied = space.get(\"occupied\")\n",
        "            class_index = CLASS_MAPPING.get(occupied, -1)\n",
        "            if class_index == -1:\n",
        "                continue\n",
        "            rotated_rect = space.find(\"rotatedRect\")\n",
        "            center = rotated_rect.find(\"center\")\n",
        "            size = rotated_rect.find(\"size\")\n",
        "            x = float(center.get(\"x\")) / IMAGE_WIDTH\n",
        "            y = float(center.get(\"y\")) / IMAGE_HEIGHT\n",
        "            w = float(size.get(\"w\")) / IMAGE_WIDTH\n",
        "            h = float(size.get(\"h\")) / IMAGE_HEIGHT\n",
        "            txt_file.write(f\"{class_index} {x} {y} {w} {h}\\n\")\n",
        "    os.remove(xml_path)\n",
        "\n",
        "print(\"Conversion complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3ifavSgoiZ5"
      },
      "source": [
        "### Remove invalid files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnFTRNzloiZ5",
        "outputId": "40cd3672-bbb0-43bc-9188-53dc2cbdf92c"
      },
      "outputs": [],
      "source": [
        "def is_valid_file(file):\n",
        "    filename = os.path.splitext(file)[0]\n",
        "    jpg_filename = filename + \".jpg\"\n",
        "    txt_filename = filename + \".txt\"\n",
        "    jpg_path = os.path.join(TRANSFORMED_DATASET_PATH, jpg_filename)\n",
        "    txt_path = os.path.join(TRANSFORMED_DATASET_PATH, txt_filename)\n",
        "    return os.path.isfile(jpg_path) and os.path.isfile(txt_path)\n",
        "\n",
        "\n",
        "for file in os.listdir(TRANSFORMED_DATASET_PATH):\n",
        "    if file == GITKEEP or file == DS_STORE:\n",
        "        continue\n",
        "    if not is_valid_file(file):\n",
        "        file_path = os.path.join(TRANSFORMED_DATASET_PATH, file)\n",
        "        os.remove(file_path)\n",
        "        print(f\"Removed file: {file_path}\")\n",
        "\n",
        "print(\"Removal complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nIlbUV9oiZ5"
      },
      "source": [
        "# Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWGJkLDroiZ6",
        "outputId": "678650c6-437f-425a-d8d0-d45dd3c28d70"
      },
      "outputs": [],
      "source": [
        "folders = [TRAINING_DATASET_PATH, VALIDATION_DATASET_PATH, TESTING_DATASET_PATH]\n",
        "for folder in folders:\n",
        "    images_path = os.path.join(folder, \"images\")\n",
        "    if not os.path.exists(images_path):\n",
        "        os.makedirs(images_path)\n",
        "    labels_path = os.path.join(folder, \"labels\")\n",
        "    if not os.path.exists(labels_path):\n",
        "        os.makedirs(labels_path)\n",
        "\n",
        "print(\"Folder creation complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOYI_1YYoiZ6",
        "outputId": "bd9deece-3e61-40e5-9456-f4bd43bfcf26"
      },
      "outputs": [],
      "source": [
        "image_files = [\n",
        "    file for file in os.listdir(TRANSFORMED_DATASET_PATH) if file.endswith(\".jpg\")\n",
        "]\n",
        "\n",
        "num_samples = len(image_files)\n",
        "num_training = int(TRAINING_RATIO * num_samples)\n",
        "num_validation = int(VALIDATION_RATIO * num_samples)\n",
        "num_testing = num_samples - num_training - num_validation\n",
        "\n",
        "random.shuffle(image_files)\n",
        "\n",
        "training_files = image_files[:num_training]\n",
        "validation_files = image_files[num_training : num_training + num_validation]\n",
        "testing_files = image_files[num_training + num_validation :]\n",
        "\n",
        "for folder, files in [\n",
        "    (TRAINING_DATASET_PATH, training_files),\n",
        "    (VALIDATION_DATASET_PATH, validation_files),\n",
        "    (TESTING_DATASET_PATH, testing_files),\n",
        "]:\n",
        "    for file in files:\n",
        "        file_label = os.path.splitext(file)[0] + \".txt\"\n",
        "\n",
        "        source_image_path = os.path.join(TRANSFORMED_DATASET_PATH, file)\n",
        "        destination_image_path = os.path.join(f\"{folder}/images\", file)\n",
        "        shutil.move(source_image_path, destination_image_path)\n",
        "\n",
        "        source_label_path = os.path.join(TRANSFORMED_DATASET_PATH, file_label)\n",
        "        destination_label_path = os.path.join(f\"{folder}/labels\", file_label)\n",
        "        shutil.move(source_label_path, destination_label_path)\n",
        "\n",
        "print(\"Splitting complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hgOC578oiZ6"
      },
      "source": [
        "# 2. Model Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YY6_MlQHoiZ6"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from ultralytics import YOLO\n",
        "\n",
        "MODEL_PATH = \"/content/drive/MyDrive/runs4/detect/train9/weights/best.pt\"\n",
        "DATASET_INFORMATION_PATH = \"/content/datasets/data.yaml\"\n",
        "\n",
        "NUM_EPOCHS = 7\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = 640\n",
        "NUM_WORKERS = 8\n",
        "DEVICE = 0 # \"gpu\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VNs7xqDoiZ7"
      },
      "outputs": [],
      "source": [
        "model = YOLO(MODEL_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOQkGbEXoiZ7"
      },
      "source": [
        "### 2.1. Fine Tunning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Kde6VSL0oiZ7",
        "outputId": "19aab63e-8489-41a9-c4e2-e0c530c1a494"
      },
      "outputs": [],
      "source": [
        "train_params = {\n",
        "    \"data\": DATASET_INFORMATION_PATH,\n",
        "    \"imgsz\": IMAGE_SIZE,\n",
        "    \"batch\": BATCH_SIZE,\n",
        "    \"epochs\": NUM_EPOCHS,\n",
        "    \"name\": \"train\",\n",
        "    \"exist_ok\": False,\n",
        "    \"weight_decay\": 0.0005,\n",
        "    \"optimizer\": \"SGD\",  # Use Adam optimizer\n",
        "    \"device\": DEVICE,\n",
        "    \"workers\": NUM_WORKERS,\n",
        "    \"resume\": False,\n",
        "}\n",
        "\n",
        "model.train(**train_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4QQMnGIoiZ7"
      },
      "source": [
        "### 2.2. Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "VBJ70bdFoiZ8",
        "outputId": "a91e3b35-7388-4a3f-b2b2-2054bd0621fa"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "test_images = \"./datasets/test/images\"\n",
        "true_labels = \"./datasets/test/labels\"\n",
        "\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "for result in predictions:\n",
        "    # Boxes object for bounding box outputs\n",
        "    boxes = result.boxes\n",
        "    # Masks object for segmentation masks outputs\n",
        "    masks = result.masks\n",
        "    # Keypoints object for pose outputs\n",
        "    keypoints = result.keypoints\n",
        "    # Probs object for classification outputs\n",
        "    probs = result.probs\n",
        "    # Oriented boxes object for OBB outputs\n",
        "    obb = result.obb\n",
        "    # display to screen\n",
        "    result.show()\n",
        "    result.save(filename='result.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UAKYXAXluFDb",
        "outputId": "11da8a17-2c92-44ae-88c1-aa3878f43b27"
      },
      "outputs": [],
      "source": [
        "results = model.val(data=\"/content/datasets/data.yaml\", split='test')  # specify 'test' to evaluate on the test set\n",
        "\n",
        "# Print results\n",
        "print(results)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GKnQaT3OB1wO",
        "outputId": "fe413d47-ae58-4985-d793-e115794d8fa1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import ultralytics\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
        "import cv2\n",
        "\n",
        "\n",
        "def load_bounding_boxes(txt_path, img_width, img_height):\n",
        "    boxes = []\n",
        "    classes = []\n",
        "    with open(txt_path, 'r') as file:\n",
        "        for line in file:\n",
        "            class_id, x_center, y_center, width, height = map(float, line.strip().split())\n",
        "            x_center *= img_width\n",
        "            y_center *= img_height\n",
        "            width *= img_width\n",
        "            height *= img_height\n",
        "            x1 = x_center - width / 2\n",
        "            y1 = y_center - height / 2\n",
        "            x2 = x_center + width / 2\n",
        "            y2 = y_center + height / 2\n",
        "            boxes.append([x1, y1, x2, y2])\n",
        "            classes.append(int(class_id))\n",
        "    return np.array(boxes), np.array(classes)\n",
        "\n",
        "\n",
        "def iou(box1, box2):\n",
        "    x1, y1, x2, y2 = box1\n",
        "    x1g, y1g, x2g, y2g = box2\n",
        "\n",
        "    xi1, yi1 = max(x1, x1g), max(y1, y1g)\n",
        "    xi2, yi2 = min(x2, x2g), min(y2, y2g)\n",
        "\n",
        "    inter_area = max(xi2 - xi1, 0) * max(yi2 - yi1, 0)\n",
        "    box1_area = (x2 - x1) * (y2 - y1)\n",
        "    box2_area = (x2g - x1g) * (y2g - y1g)\n",
        "\n",
        "    union_area = box1_area + box2_area - inter_area\n",
        "\n",
        "    return inter_area / union_area if union_area != 0 else 0\n",
        "\n",
        "\n",
        "print(f\"Mean Average Precision (mAP@0.5): {results.box.maps[0]}\")\n",
        "print(f\"Mean Average Precision (mAP@0.5:0.95): {results.box.maps[1]}\")\n",
        "\n",
        "\n",
        "true_classes = []\n",
        "pred_classes = []\n",
        "\n",
        "test_images_path = '/content/datasets/test/images'\n",
        "test_labels_path = '/content/datasets/test/labels'\n",
        "test_images = os.listdir(test_images_path)\n",
        "\n",
        "for img_file in test_images:\n",
        "    img_path = os.path.join(test_images_path, img_file)\n",
        "    label_path = os.path.join(test_labels_path, os.path.splitext(img_file)[0] + '.txt')\n",
        "\n",
        "    img = cv2.imread(img_path)\n",
        "    img_height, img_width, _ = img.shape\n",
        "\n",
        "    ground_truth_boxes, ground_truth_classes = load_bounding_boxes(label_path, img_width, img_height)\n",
        "\n",
        "    prediction_results = model(img_path)\n",
        "    predicted_boxes = prediction_results[0].boxes.xyxy.cpu().numpy()\n",
        "    predicted_classes = prediction_results[0].boxes.cls.cpu().numpy().astype(int)\n",
        "\n",
        "    for gt_box, gt_class in zip(ground_truth_boxes, ground_truth_classes):\n",
        "        if len(predicted_boxes) > 0:\n",
        "            ious = [iou(gt_box, pred_box) for pred_box in predicted_boxes]\n",
        "            max_iou_idx = np.argmax(ious)\n",
        "            if ious[max_iou_idx] > 0.5:  # arbitrary true positive threshold\n",
        "                true_classes.append(gt_class)\n",
        "                pred_classes.append(predicted_classes[max_iou_idx])\n",
        "            else:\n",
        "                true_classes.append(gt_class)\n",
        "                pred_classes.append(-1)  # False negative\n",
        "        else:\n",
        "            true_classes.append(gt_class)\n",
        "            pred_classes.append(-1)  # False negative\n",
        "\n",
        "    for pred_box, pred_class in zip(predicted_boxes, predicted_classes):\n",
        "        if not any([iou(pred_box, gt_box) > 0.5 for gt_box in ground_truth_boxes]):\n",
        "            true_classes.append(-1)  # False positive\n",
        "            pred_classes.append(pred_class)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "id": "YX--lh7xOuUu",
        "outputId": "6c78d173-fb6e-4dfd-dc7d-125f5e2f8148"
      },
      "outputs": [],
      "source": [
        "labels = [-1, 0, 1]\n",
        "cm = confusion_matrix(true_classes, pred_classes, labels=labels)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['background', 'empty', 'occupied'])\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "report = classification_report(true_classes, pred_classes, target_names=['background', 'empty', 'occupied'])\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kr-6pPrYbnqx",
        "outputId": "35af167a-96b4-4b4d-e09e-2965bdffe195"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import (\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    matthews_corrcoef,\n",
        "    confusion_matrix,\n",
        "    accuracy_score,\n",
        ")\n",
        "\n",
        "def printClassResults(model_name, truth, preds):\n",
        "    print(\"The Model is: %s\" % model_name)\n",
        "    print(\"The Accuracy is: %7.4f\" % accuracy_score(truth, preds))\n",
        "    print(\"The Precision is: %7.4f\" % precision_score(truth, preds, average=\"weighted\"))\n",
        "    print(\"The Recall is: %7.4f\" % recall_score(truth, preds, average=\"weighted\"))\n",
        "    print(\"The F1 score is: %7.4f\" % f1_score(truth, preds, average=\"weighted\"))\n",
        "    print(\n",
        "        \"The Matthews correlation coefficient is: %7.4f\"\n",
        "        % matthews_corrcoef(truth, preds)\n",
        "    )\n",
        "    print()\n",
        "\n",
        "\n",
        "printClassResults(\"Yolov8 model\", true_classes, pred_classes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuCo_SByoiZ9",
        "outputId": "18adab04-f6ce-4add-d2a0-9828fe6525db"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_images_directory = \"./datasets/test/images\"\n",
        "\n",
        "image_files = [f for f in os.listdir(test_images_directory) if f.lower().endswith(\".jpg\")]\n",
        "\n",
        "random_image_filename = random.choice(image_files)\n",
        "random_image_path = os.path.join(test_images_directory, random_image_filename)\n",
        "\n",
        "results = model.predict(random_image_path)\n",
        "\n",
        "result = results[0]\n",
        "\n",
        "print(len(result.boxes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QLKdji6oiZ9"
      },
      "outputs": [],
      "source": [
        "backup = random_image_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9QAmsNroiZ9",
        "outputId": "3dea5789-8f43-4765-a19d-1cf8bc8e1a13"
      },
      "outputs": [],
      "source": [
        "for box in result.boxes:\n",
        "\tlabel = result.names[box.cls[0].item()]\n",
        "\tcoords = [round(x) for x in box.xyxy[0].tolist()]\n",
        "\tprob = round(box.conf[0].item(), 4)\n",
        "\tprint(\"Object: {}\\nCoordinates: {}\\nProbability: {}\".format(label, coords, prob))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "TziJAX1QoiZ-",
        "outputId": "46d8f99d-692e-4c40-c9d5-5bc77fd73a7c"
      },
      "outputs": [],
      "source": [
        "# Original image\n",
        "\n",
        "Image.open(random_image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "TI201PqeoiZ-",
        "outputId": "bea6632e-0f21-48a6-8cb4-00d887a43853"
      },
      "outputs": [],
      "source": [
        "# Image with the result of the model\n",
        "\n",
        "Image.fromarray(result.plot()[:,:,::-1])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
